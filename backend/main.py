"""
Aetherium Platform - Advanced FastAPI Backend
Integrates Advanced Platform Orchestrator with comprehensive API endpoints
"""

from fastapi import FastAPI, HTTPException, BackgroundTasks, Depends
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse, JSONResponse
from pydantic import BaseModel, Field
from typing import Dict, List, Optional, Any
import asyncio
import logging
import time
from datetime import datetime

# Import advanced platform components
from ai_ml.advanced_platform_orchestrator import platform_orchestrator, SystemStatus
from ai_ml.ai_engine import ProcessingMode

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Initialize FastAPI app
app = FastAPI(
    title="Aetherium Advanced AI Platform",
    description="Quantum-Enhanced AI Platform with MCP & A2A Communication",
    version="3.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Pydantic models for API requests/responses
class QueryRequest(BaseModel):
    query: str = Field(..., description="The query to process")
    user_id: str = Field(..., description="User identifier")
    session_id: Optional[str] = Field(None, description="Session identifier for context persistence")
    processing_options: Optional[Dict[str, Any]] = Field(default_factory=dict, description="Processing configuration options")
    
    class Config:
        schema_extra = {
            "example": {
                "query": "Analyze quantum market trends and predict future performance",
                "user_id": "user123",
                "session_id": "session_abc",
                "processing_options": {
                    "use_quantum": True,
                    "neural_complexity": 5,
                    "parallelism": 3,
                    "force_mode": "hybrid"
                }
            }
        }

class QueryResponse(BaseModel):
    response: str
    confidence: float
    processing_mode: str
    total_processing_time_ms: float
    resource_allocation: Dict[str, Any]
    ai_metrics: Dict[str, Any]
    quantum_enhanced: bool
    temporal_processed: bool
    session_id: Optional[str]
    platform_status: str

class PlatformStatusResponse(BaseModel):
    platform_status: str
    uptime_seconds: float
    startup_time: Optional[str]
    active_sessions: int
    system_metrics: Optional[Dict[str, Any]]
    a2a_statistics: Dict[str, Any]
    mcp_statistics: Dict[str, Any]
    component_health: Dict[str, Any]
    recent_alerts: List[Dict[str, Any]]
    configuration: Dict[str, Any]

class HealthResponse(BaseModel):
    status: str
    timestamp: str
    platform_initialized: bool
    services_active: List[str]
    services_inactive: List[str]

# Platform initialization status
platform_initialized = False

async def get_platform_orchestrator():
    """Dependency to get the platform orchestrator instance"""
    global platform_initialized
    
    if not platform_initialized:
        success = await platform_orchestrator.initialize_platform()
        if success:
            platform_initialized = True
            logger.info("üöÄ Platform orchestrator initialized successfully")
        else:
            raise HTTPException(status_code=500, detail="Platform initialization failed")
    
    return platform_orchestrator

@app.on_event("startup")
async def startup_event():
    """Initialize the platform on startup"""
    global platform_initialized
    
    logger.info("üöÄ Starting Aetherium Advanced AI Platform...")
    
    try:
        # Initialize platform orchestrator
        success = await platform_orchestrator.initialize_platform()
        if success:
            platform_initialized = True
            logger.info("‚úÖ Platform startup complete - all systems operational")
        else:
            logger.error("‚ùå Platform startup failed")
    except Exception as e:
        logger.error(f"‚ùå Startup error: {e}")

@app.on_event("shutdown")
async def shutdown_event():
    """Gracefully shutdown the platform"""
    global platform_initialized
    
    logger.info("üîÑ Shutting down Aetherium Platform...")
    
    try:
        if platform_initialized:
            await platform_orchestrator.shutdown_platform()
            platform_initialized = False
            logger.info("‚úÖ Platform shutdown complete")
    except Exception as e:
        logger.error(f"‚ùå Shutdown error: {e}")

# API Routes

@app.get("/", response_class=HTMLResponse)
async def root():
    """Root endpoint with platform information"""
    return """
    <!DOCTYPE html>
    <html>
    <head>
        <title>Aetherium Advanced AI Platform</title>
        <style>
            body { font-family: Arial, sans-serif; margin: 40px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; }
            .container { max-width: 800px; margin: 0 auto; background: rgba(255,255,255,0.1); padding: 30px; border-radius: 15px; backdrop-filter: blur(10px); }
            h1 { text-align: center; margin-bottom: 30px; font-size: 2.5em; }
            .feature { margin: 20px 0; padding: 15px; background: rgba(255,255,255,0.1); border-radius: 10px; }
            .emoji { font-size: 1.5em; margin-right: 10px; }
            a { color: #87CEEB; text-decoration: none; }
            a:hover { text-decoration: underline; }
            .status { text-align: center; margin: 20px 0; }
        </style>
    </head>
    <body>
        <div class="container">
            <h1>üåå Aetherium Advanced AI Platform</h1>
            
            <div class="status">
                <h2>üöÄ Quantum-Enhanced AI Platform Active</h2>
                <p>Advanced MCP & A2A Communication ‚Ä¢ Real-time Performance Monitoring</p>
            </div>
            
            <div class="feature">
                <span class="emoji">ü§ñ</span>
                <strong>Quantum-Enhanced AI Engine:</strong> Multi-modal processing with neural-quantum hybrid capabilities and time crystal acceleration
            </div>
            
            <div class="feature">
                <span class="emoji">üîó</span>
                <strong>Agent-to-Agent Communication:</strong> Advanced multi-agent orchestration with intelligent routing and fault tolerance
            </div>
            
            <div class="feature">
                <span class="emoji">üîÆ</span>
                <strong>Model Context Protocol:</strong> Enhanced context sharing with compression, encryption, and distributed storage
            </div>
            
            <div class="feature">
                <span class="emoji">üìä</span>
                <strong>Performance Monitoring:</strong> Real-time system optimization with automated performance tuning
            </div>
            
            <div class="feature">
                <span class="emoji">‚ö°</span>
                <strong>Resource Management:</strong> Intelligent allocation of quantum processors, neural networks, and time crystals
            </div>
            
            <div class="status">
                <h3>API Documentation</h3>
                <p>
                    <a href="/docs">üìö Interactive API Docs (Swagger)</a> | 
                    <a href="/redoc">üìñ API Documentation (ReDoc)</a> |
                    <a href="/health">üíì Health Check</a> |
                    <a href="/platform/status">üìä Platform Status</a>
                </p>
            </div>
        </div>
    </body>
    </html>
    """

@app.get("/health", response_model=HealthResponse)
async def health_check():
    """Comprehensive health check endpoint"""
    
    services_active = []
    services_inactive = []
    
    # Check platform orchestrator status
    if platform_initialized and platform_orchestrator.platform_status == SystemStatus.ACTIVE:
        services_active.extend([
            "platform_orchestrator",
            "mcp_handler", 
            "a2a_engine",
            "ai_engine",
            "resource_manager",
            "performance_monitor"
        ])
    else:
        services_inactive.extend([
            "platform_orchestrator",
            "mcp_handler", 
            "a2a_engine",
            "ai_engine",
            "resource_manager",
            "performance_monitor"
        ])
    
    status = "healthy" if len(services_active) > len(services_inactive) else "degraded"
    
    return HealthResponse(
        status=status,
        timestamp=datetime.now().isoformat(),
        platform_initialized=platform_initialized,
        services_active=services_active,
        services_inactive=services_inactive
    )

@app.post("/ai/query", response_model=QueryResponse)
async def process_ai_query(
    request: QueryRequest,
    orchestrator = Depends(get_platform_orchestrator)
):
    """Process advanced AI query through the platform orchestrator"""
    
    try:
        start_time = time.time()
        
        # Process query through platform orchestrator
        result = await orchestrator.process_intelligent_query(
            query=request.query,
            user_id=request.user_id,
            session_id=request.session_id,
            processing_options=request.processing_options
        )
        
        processing_time = (time.time() - start_time) * 1000
        logger.info(f"‚úÖ Query processed in {processing_time:.1f}ms")
        
        return QueryResponse(**result)
        
    except Exception as e:
        logger.error(f"‚ùå Error processing query: {e}")
        raise HTTPException(status_code=500, detail=f"Query processing failed: {str(e)}")

@app.get("/platform/status", response_model=PlatformStatusResponse)
async def get_platform_status(
    orchestrator = Depends(get_platform_orchestrator)
):
    """Get comprehensive platform status and metrics"""
    
    try:
        status_data = await orchestrator.get_platform_status()
        return PlatformStatusResponse(**status_data)
        
    except Exception as e:
        logger.error(f"‚ùå Error getting platform status: {e}")
        raise HTTPException(status_code=500, detail=f"Status retrieval failed: {str(e)}")

@app.post("/platform/initialize")
async def initialize_platform():
    """Manually initialize the platform (if not auto-initialized)"""
    
    global platform_initialized
    
    if platform_initialized:
        return {"message": "Platform already initialized", "status": "success"}
    
    try:
        success = await platform_orchestrator.initialize_platform()
        if success:
            platform_initialized = True
            return {"message": "Platform initialized successfully", "status": "success"}
        else:
            return {"message": "Platform initialization failed", "status": "error"}
            
    except Exception as e:
        logger.error(f"‚ùå Manual initialization error: {e}")
        raise HTTPException(status_code=500, detail=f"Initialization failed: {str(e)}")

@app.post("/platform/shutdown")
async def shutdown_platform():
    """Manually shutdown the platform"""
    
    global platform_initialized
    
    if not platform_initialized:
        return {"message": "Platform not initialized", "status": "info"}
    
    try:
        await platform_orchestrator.shutdown_platform()
        platform_initialized = False
        return {"message": "Platform shutdown successfully", "status": "success"}
        
    except Exception as e:
        logger.error(f"‚ùå Manual shutdown error: {e}")
        raise HTTPException(status_code=500, detail=f"Shutdown failed: {str(e)}")

@app.get("/ai/models")
async def get_ai_models(
    orchestrator = Depends(get_platform_orchestrator)
):
    """Get available AI models and their capabilities"""
    
    try:
        models_info = []
        for model in orchestrator.ai_engine.models:
            models_info.append({
                "model_id": model.model_id,
                "model_type": model.model_type.value,
                "capabilities": [cap.value for cap in model.capabilities],
                "performance_score": model.performance_score,
                "resource_requirements": model.resource_requirements
            })
        
        return {
            "models": models_info,
            "total_models": len(models_info),
            "processing_modes": [mode.value for mode in ProcessingMode]
        }
        
    except Exception as e:
        logger.error(f"‚ùå Error getting AI models: {e}")
        raise HTTPException(status_code=500, detail=f"Models retrieval failed: {str(e)}")

@app.get("/platform/metrics")
async def get_platform_metrics(
    orchestrator = Depends(get_platform_orchestrator)
):
    """Get detailed platform performance metrics"""
    
    try:
        metrics_history = list(orchestrator.performance_monitor.metrics_history)
        
        if not metrics_history:
            return {"message": "No metrics available yet", "metrics": []}
        
        # Return last 10 metrics with timestamps
        recent_metrics = []
        for i, metrics in enumerate(metrics_history[-10:]):
            recent_metrics.append({
                "timestamp": datetime.now().isoformat(),  # In real implementation, use actual timestamp
                "cpu_usage": metrics.cpu_usage,
                "memory_usage_mb": metrics.memory_usage_mb,
                "network_latency_ms": metrics.network_latency_ms,
                "active_agents": metrics.active_agents,
                "active_contexts": metrics.active_contexts,
                "query_processing_rate": metrics.query_processing_rate,
                "error_rate": metrics.error_rate,
                "quantum_advantage_avg": metrics.quantum_advantage_avg,
                "system_efficiency": metrics.system_efficiency
            })
        
        return {
            "metrics": recent_metrics,
            "total_data_points": len(metrics_history),
            "monitoring_active": orchestrator.performance_monitor.monitoring_active
        }
        
    except Exception as e:
        logger.error(f"‚ùå Error getting platform metrics: {e}")
        raise HTTPException(status_code=500, detail=f"Metrics retrieval failed: {str(e)}")

@app.get("/platform/alerts")
async def get_platform_alerts(
    orchestrator = Depends(get_platform_orchestrator)
):
    """Get recent platform alerts and notifications"""
    
    try:
        alerts = list(orchestrator.performance_monitor.alerts)
        
        # Format alerts for API response
        formatted_alerts = []
        for alert in alerts:
            formatted_alerts.append({
                "timestamp": alert['timestamp'].isoformat(),
                "message": alert['message'],
                "priority": alert['priority'],
                "alert_id": alert['alert_id']
            })
        
        return {
            "alerts": formatted_alerts,
            "total_alerts": len(formatted_alerts),
            "alert_levels": ["info", "warning", "critical"]
        }
        
    except Exception as e:
        logger.error(f"‚ùå Error getting platform alerts: {e}")
        raise HTTPException(status_code=500, detail=f"Alerts retrieval failed: {str(e)}")

# WebSocket endpoint for real-time updates (future enhancement)
@app.websocket("/ws/platform")
async def platform_websocket(websocket):
    """WebSocket endpoint for real-time platform updates"""
    await websocket.accept()
    
    try:
        while True:
            # Send real-time platform status
            if platform_initialized:
                status = await platform_orchestrator.get_platform_status()
                await websocket.send_json({
                    "type": "status_update",
                    "data": status,
                    "timestamp": datetime.now().isoformat()
                })
            
            await asyncio.sleep(5)  # Update every 5 seconds
            
    except Exception as e:
        logger.error(f"WebSocket error: {e}")
    finally:
        await websocket.close()

if __name__ == "__main__":
    import uvicorn
    
    logger.info("üöÄ Starting Aetherium Advanced AI Platform Server...")
    
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )
